x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: ./airflow/Dockerfile
  env_file:
    - ${ENV_FILE_PATH:-.env}
  environment: &airflow-common-env
    # SỬ DỤNG LOCAL EXECUTOR
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    # Kết nối DB cho Airflow
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    
    # dbt Configuration
    DBT_PROFILES_DIR: /opt/dbt_profiles
    DBT_PROJECT_DIR: /opt/dbt_project
    DBT_TARGET: dev
    DBT_LOG_PATH: /tmp/dbt_logs
    DBT_TARGET_PATH: /tmp/dbt_target
    
    # Iceberg Configuration
    ICEBERG_CATALOG: ${ICEBERG_CATALOG}
    BRONZE_NAMESPACE: ${BRONZE_NAMESPACE}
    SILVER_NAMESPACE: ${SILVER_NAMESPACE}
    GOLD_NAMESPACE: ${GOLD_NAMESPACE}
    SILVER_TABLE: ${SILVER_TABLE}
    
    # Spark Connection
    SPARK_HOST: ${SPARK_HOST}
    SPARK_THRIFT_PORT: ${SPARK_THRIFT_PORT}
    SPARK_USER: ${SPARK_USER}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./metric_collector/app/schema:/opt/airflow/schemas
    - ./dbt_project:/opt/dbt_project
    - ./dbt_profiles:/opt/dbt_profiles
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy
  networks:
      - data_stack_net

# --------------------------------------------------------------------------------------
services:
  #____________________POSTGRES____________________
  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      - data_stack_net

  #____________________AIRFLOW____________________
  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins
        chown -R "${AIRFLOW_UID}:0" /opt/airflow/{logs,dags,plugins}
        exec /entrypoint airflow version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: 'admin'
      _AIRFLOW_WWW_USER_PASSWORD: 'admin'
    user: "0:0"

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      <<: *airflow-common-depends-on
    networks:
      - data_stack_net

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $$(hostname)"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    networks:
      - data_stack_net

  airflow-triggerer:
    <<: *airflow-common
    container_name: airflow-triggerer
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type TriggererJob --hostname $$(hostname)"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully 
    networks:
      - data_stack_net

  #____________________KAFKA____________________
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - data_stack_net

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    volumes:
      - kafka-data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      # Data retention settings
      KAFKA_LOG_RETENTION_HOURS: 168        # 7 ngày
      KAFKA_LOG_RETENTION_BYTES: 1073741824 # 1GB per partition
      KAFKA_LOG_SEGMENT_BYTES: 1073741824   # 1GB per segment
    networks:
      - data_stack_net

  #____________________ICEBERG____________________
  spark-iceberg:
    image: tabulario/spark-iceberg
    container_name: spark-iceberg
    entrypoint: ["/bin/bash"]
    command:
      - -c
      - |
        SPARK_OPTS="--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
        --conf spark.sql.catalog.demo=org.apache.iceberg.spark.SparkCatalog \
        --conf spark.sql.catalog.demo.type=rest \
        --conf spark.sql.catalog.demo.uri=http://rest:8181 \
        --conf spark.sql.catalog.demo.warehouse=s3a://warehouse/ \
        --conf spark.sql.catalog.demo.io-impl=org.apache.iceberg.aws.s3.S3FileIO \
        --conf spark.sql.catalog.demo.s3.endpoint=http://minio:9000 \
        --conf spark.sql.catalog.demo.s3.path-style-access=true \
        --conf spark.hadoop.fs.s3a.access.key=$${MINIO_ROOT_USER} \
        --conf spark.hadoop.fs.s3a.secret.key=$${MINIO_ROOT_PASSWORD} \
        --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
        --conf spark.hadoop.fs.s3a.path.style.access=true \
        --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false \
        --conf spark.sql.defaultCatalog=demo"

        /opt/spark/sbin/start-thriftserver.sh \
          --master local[*] \
          $$SPARK_OPTS \
          --conf spark.driver.memory=1g \
          --conf spark.executor.memory=1g
        
        # Wait for Thrift Server to fully start
        sleep 10
        
        # Initialize infrastructure schemas
        spark-sql --master local[*] $$SPARK_OPTS -e "CREATE NAMESPACE IF NOT EXISTS demo.default;"
        spark-sql --master local[*] $$SPARK_OPTS -e "CREATE NAMESPACE IF NOT EXISTS demo.bronze;"
        spark-sql --master local[*] $$SPARK_OPTS -e "CREATE NAMESPACE IF NOT EXISTS demo.silver;"
        spark-sql --master local[*] $$SPARK_OPTS -e "CREATE NAMESPACE IF NOT EXISTS demo.gold;"
        
        # Start Jupyter in foreground to keep container alive
        ./entrypoint.sh notebook
    networks:
      - data_stack_net
    depends_on:
      - rest
      - minio
    volumes:
      - ./warehouse:/home/iceberg/warehouse
      - ./notebooks:/home/iceberg/notebooks/notebooks
      - ./dags/spark_jobs:/home/iceberg/spark_jobs
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
      - AWS_REGION=us-east-1
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    ports:
      - 8888:8888 # Jupyter
      - 8081:8080 # Spark UI
      - 10000:10000 # Spark Thrift Server

  rest:
    image: apache/iceberg-rest-fixture
    container_name: iceberg-rest
    networks:
      - data_stack_net
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://${MINIO_BUCKET}/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000

  #____________________MINIO____________________
  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_DOMAIN=minio
    networks:
      data_stack_net:
        aliases:
          - ${MINIO_BUCKET}.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - minio-data:/data

  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      - data_stack_net
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc mb minio/${MINIO_BUCKET} || true;
      /usr/bin/mc policy set public minio/${MINIO_BUCKET};
      tail -f /dev/null
      "

#____________________VOLUMES & NETWORKS____________________
volumes:
  postgres-db-volume:
  minio-data:
  kafka-data:
  zookeeper-data:
  zookeeper-logs:

networks:
  data_stack_net: