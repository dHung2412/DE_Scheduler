# Data Pipeline for GitHub Events 

D·ª± √°n n√†y tri·ªÉn khai m·ªôt Data Pipeline to√†n di·ªán (End-to-End), ƒë∆∞·ª£c thi·∫øt k·ªÉ ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu s·ª± ki·ªán th·ªùi gian th·ª±c t·ª´ GitHub, s·ª≠ d·ª•ng ki·∫øn tr√∫c Lakehouse hi·ªán ƒë·∫°i.

## üõ† Tech Stack
*   **Ingestion**: FastAPI & Kafka
*   **Orchestration**: [Apache Airflow](https://airflow.apache.org/)
*   **Processing Engine**: [Apache Spark](https://spark.apache.org/) (Streaming & Batch)
*   **Table Format**: [Apache Iceberg](https://iceberg.apache.org/)
*   **Transformation**: [dbt](https://www.getdbt.com/)
*   **Storage**: [MinIO](https://min.io/) (S3 Compatible)
*   **Infrastructure**: Docker & Docker Compose

## üìÇ Project Structure
- `airflow/`: C·∫•u h√¨nh Docker build v√† Plugins cho Airflow.
- `dags/`: Ch·ª©a c√°c pipeline ƒëi·ªÅu ph·ªëi (DAGs) v√† code Spark.
- `dbt_project/`: Project dbt qu·∫£n l√Ω logic transform d·ªØ li·ªáu (Silver -> Gold).
- `metric_collector/`: Service API nh·∫≠n d·ªØ li·ªáu v√† Kafka Producer.
- `docker-compose.yaml`: ƒê·ªãnh nghƒ©a to√†n b·ªô h·∫° t·∫ßng (Infrastructure as Code).

## üèó Ki·∫øn tr√∫c h·ªá th·ªëng (Architecture)
H·ªá th·ªëng s·ª≠ d·ª•ng ki·∫øn tr√∫c **Lambda Architecture**, k·∫øt h·ª£p gi·ªØa Streaming (Ingestion) v√† Batch (Processing).

![Pipeline Architecture](./utils/pipeline.png)

### Detailed Pipeline Flow

**1. Ingestion Layer: API & Kafka (High Throughput & Reliability)**
*   **API Gateway**: Thi·∫øt k·∫ø theo h∆∞·ªõng **Non-blocking I/O** & **Fail-Fast**.
    *   Nh·∫≠n payload JSON -> G√°n Trace ID (`event_id`) -> ƒê·∫©y v√†o Memory Queue (`put_nowait`).
    *   Ph·∫£n h·ªìi client t·ª©c th√¨ v·ªõi ƒë·ªô tr·ªÖ c·ª±c th·∫•p (<10ms).
    *   C∆° ch·∫ø **Backpressure**: Tr·∫£ v·ªÅ `503 Service Unavailable` khi h√†ng ƒë·ª£i ƒë·∫ßy ƒë·ªÉ b·∫£o v·ªá t√†i nguy√™n server.
*   **Producer Worker**:
    *   **Hybrid Batching Strategy**: T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi gi·ªØa 'Polling' (High Load) v√† 'Waiting' (Low Latency) ƒë·ªÉ t·ªëi ∆∞u throughput.
    *   **Non-blocking Serialization**: D√πng `run_in_executor` ƒë·ªÉ ƒë·∫©y t√°c v·ª• n√©n Avro (CPU-bound) sang thread ri√™ng, gi·ªØ cho Event Loop lu√¥n m∆∞·ª£t m√†.
    *   **Data Durability**: C∆° ch·∫ø Retry k·∫øt h·ª£p **Local Fallback** gi√∫p ƒë·∫£m b·∫£o kh√¥ng m·∫•t m√°t d·ªØ li·ªáu (Zero Data Loss) k·ªÉ c·∫£ khi Kafka g·∫∑p s·ª± c·ªë.

**2. Bronze Layer: Streaming Ingestion (Kafka -> Iceberg)**
*   Spark Structured Streaming ƒë·ªçc li√™n t·ª•c t·ª´ Kafka topic.
*   S·ª≠ d·ª•ng **UDF Decoder** gi·∫£i m√£ Avro binary ngay trong Spark.
*   **Flattening**: L√†m ph·∫≥ng c·∫•u tr√∫c JSON l·ªìng nhau.
*   Ghi v√†o b·∫£ng Iceberg `demo.bronze.github_events` v·ªõi ch·∫ø ƒë·ªô Fanout Writer.

**3. Silver Layer (Part 1): Raw to Structured (Spark Batch)**
*   Trigger b·ªüi Airflow ƒë·ªãnh k·ª≥ (Hourly).
*   **Incremental Load**: Ch·ªâ ƒë·ªçc d·ªØ li·ªáu m·ªõi t·ª´ Bronze d·ª±a v√†o watermark `ingestion_timestamp`.
*   **Parsing**: Parse c·ªôt `payload` JSON th√†nh c√°c c·ªôt quan tr·ªçng (PR details, Issue state...).
*   **Append Only**: Chi·∫øn l∆∞·ª£c ghi nh·∫≠n s·ª± ki·ªán l·ªãch s·ª≠, kh√¥ng update/delete ƒë·ªÉ t·ªëi ∆∞u performace (No MoR overhead).

**4. Silver Layer (Part 2): Structured to Enriched (dbt)**
*   L√†m s·∫°ch d·ªØ li·ªáu, chu·∫©n h√≥a ƒë·ªãnh d·∫°ng chu·ªói.
*   **Event Categorization**: Ph√¢n lo·∫°i s·ª± ki·ªán (Code Change, Social, Management...).
*   T√≠nh to√°n Activity Score cho t·ª´ng event.

**5. Gold Layer: Aggregation & Business Insights (dbt)**
*   **Daily Aggregation**: T·ªïng h·ª£p ho·∫°t ƒë·ªông ng∆∞·ªùi d√πng theo ng√†y.
*   **User Profiling**: Ph√¢n lo·∫°i User (Developer, Reviewer, etc.) d·ª±a tr√™n h√†nh vi ƒë√≥ng g√≥p.
*   T√≠nh to√°n c√°c ch·ªâ s·ªë xu h∆∞·ªõng (Rolling Average).

**6. Orchestration**
*   **Airflow DAG** ch·∫°y ƒë·ªãnh k·ª≥ m·ªói gi·ªù:
    1.  `Spark Job`: Bronze -> Silver Parsed.
    2.  `dbt run`: Silver Enriched update.
    3.  `dbt run`: Gold User Activity update.
    4.  `dbt test`: Ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu (Unique ID, Not Null...).

**7. Maintenance Layer (Iceberg Table Optimization)**
H·ªá th·ªëng Iceberg c·∫ßn ƒë∆∞·ª£c b·∫£o tr√¨ ƒë·ªãnh k·ª≥ ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ "Small Files" (do Streaming) v√† "Metadata Bloat" (do time travel history).

*   **Daily Maintenance**: (`maintenance_{bronze|silver}_by_day.py`)
    *   **M·ª•c ti√™u**: T·ªëi ∆∞u hi·ªáu su·∫•t ƒê·ªåC v√† L∆ØU TR·ªÆ.
    *   **Compaction**: Gom c√°c file nh·ªè (do streaming/batch nh·ªè sinh ra) th√†nh file chu·∫©n (20MB).
    *   **Data Layout Optimization (Silver only)**: S·ª≠ d·ª•ng chi·∫øn thu·∫≠t **Sort (Z-Order)** theo `event_type` & `created_at`. Gi√∫p Query Engine b·ªè qua (Skip) d·ªØ li·ªáu kh√¥ng c·∫ßn thi·∫øt khi l·ªçc, tƒÉng t·ªëc ƒë·ªô truy v·∫•n ƒë√°ng k·ªÉ.
    *   **Cost Efficiency**: S·ª≠ d·ª•ng r√†ng bu·ªôc `min-input-files` ƒë·ªÉ tr√°nh ch·∫°y job l√£ng ph√≠ khi d·ªØ li·ªáu √≠t, v√† `cutoff` date ƒë·ªÉ ch·ªâ x·ª≠ l√Ω d·ªØ li·ªáu m·ªõi.

*   **Weekly Maintenance**: (`maintenance_{bronze|silver}_by_week.py`)
    *   **M·ª•c ti√™u**: D·ªçn d·∫πp r√°c h·ªá th·ªëng & Gi·∫£i ph√≥ng dung l∆∞·ª£ng.
    *   **Expire Snapshots**: X√≥a b·ªè c√°c metadata check-points c≈© (> 7 ng√†y). Gi·ªØ l·∫°i t·ªëi thi·ªÉu 5 snapshots g·∫ßn nh·∫•t ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n cho Time Travel.
    *   **Remove Orphan Files**: X√≥a d·ª©t ƒëi·ªÉm c√°c file v·∫≠t l√Ω tr√¥i n·ªïi kh√¥ng c√≤n ƒë∆∞·ª£c tham chi·∫øu b·ªüi b·∫•t k·ª≥ snapshot n√†o.
    *   **Rewrite Position Deletes**: Kh√¥ng √°p d·ª•ng (V√¨ h·ªá th·ªëng thi·∫øt k·∫ø d·∫°ng Append-Only).

## üöÄ Getting Started

### 1. Prerequisites
- Docker & Docker Compose installed.
- RAM t·ªëi thi·ªÉu: 6-8GB.

### 2. Setup Environment
T·∫°o file `.env` t·∫°i th∆∞ m·ª•c g·ªëc v√† c·∫•u h√¨nh c√°c th√¥ng s·ªë k·∫øt n·ªëi (tham kh·∫£o file `docker-compose.yaml`):
